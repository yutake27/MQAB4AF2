{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate MQA performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "plt.rcParams[\"figure.dpi\"] = 150\n",
    "sns.set(style='darkgrid')\n",
    "from IPython.display import display\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', UserWarning)\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['mathtext.fontset'] = 'stix'\n",
    "plt.rcParams[\"font.size\"] = 15\n",
    "plt.rcParams['figure.figsize'] = (6, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('../../../../../data/')\n",
    "dataset_dir = data_dir / 'out' / 'dataset'\n",
    "subset_name = 'target_subset_' + Path('.').resolve().parent.name\n",
    "score_dir = dataset_dir / 'score' / 'subsets' / subset_name\n",
    "assert score_dir.exists()\n",
    "fig_dir = score_dir / 'fig' / 'MQA'\n",
    "fig_dir.mkdir(parents=True, exist_ok=True)\n",
    "target_list = data_dir / 'interim' / f'{subset_name}.csv'\n",
    "domain_csv = data_dir / 'interim' / 'ecod_domain_num.csv'\n",
    "assert target_list.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_path = score_dir / 'label.csv'\n",
    "label_df = pd.read_csv(label_path, index_col=0)\n",
    "target_df = pd.read_csv(target_list, index_col=0)\n",
    "neff_df = pd.read_csv(score_dir / 'neff.csv', index_col=0)\n",
    "domain_df = pd.read_csv(domain_csv)\n",
    "target_df = pd.merge(target_df, domain_df, on='id', how='left')\n",
    "target_df = pd.merge(target_df, neff_df, left_on='id', right_on='Target').drop('id', axis=1)\n",
    "label_df = pd.merge(label_df, target_df, on='Target', how='left')\n",
    "label_df = label_df.drop(['pLDDT', 'pTMscore'], axis=1)\n",
    "label_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, csv in enumerate(sorted(score_dir.glob('*.csv.gz'))):\n",
    "    if csv.name == 'all_score.csv.gz':\n",
    "        continue\n",
    "    method_df = pd.read_csv(csv, index_col=0)\n",
    "    if csv.name in ['ProQ3D_resolved.csv.gz', 'DOPE_resolved.csv.gz', 'SBROD_resolved.csv.gz']:\n",
    "        method_names = set(method_df.columns.tolist()) - {'Target', 'Model'}\n",
    "        method_df = method_df.rename({method_name: f'{method_name}_resolved' for method_name in method_names}, axis=1)\n",
    "    if i == 0:\n",
    "        mqa_df = method_df\n",
    "        continue\n",
    "    mqa_df = pd.merge(mqa_df, method_df, on=['Model', 'Target'], how='outer')\n",
    "mqa_df['DOPE_resolved'] = - mqa_df['DOPE_resolved']\n",
    "mqa_df['SOAP_resolved'] = - mqa_df['SOAP_resolved']\n",
    "mqa_df = mqa_df.rename({m: m.split('_')[0] for m in mqa_df.columns.tolist() if '_resolved' in m}, axis=1)\n",
    "mqa_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(label_df, mqa_df, on=['Target', 'Model'], how='left')\n",
    "df_output_path = score_dir / 'all_score.csv.gz'\n",
    "save_df = df.drop(['header', 'sequence'], axis=1)\n",
    "save_df.to_csv(df_output_path, compression='gzip')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../../mqa')\n",
    "from eval import eval, stat_test, eval_get_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mqa_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate MQA peformance per target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For GDT_TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Against gdtts\n",
    "mqa_methods = ['DOPE', 'SOAP', 'ProQ3D', 'SBROD', 'VoroCNN', 'Sato-3DCNN', 'P3CMQA', 'DeepAccNet', 'DeepAccNet-Bert']\n",
    "methods = mqa_methods + ['pLDDT', 'pTM']\n",
    "label = 'GDT_TS'\n",
    "data = df\n",
    "result_df = eval(data, methods, label_name=label)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Against gdtts\n",
    "label = 'GDT_TS'\n",
    "data = df.groupby('Target').filter(lambda x: x[label].max() - x[label].min() > 0.05)\n",
    "result_each_target = eval_get_df(data, methods, label_name=label)\n",
    "def get_whole_result_from_each_target(result_each_target, columns):\n",
    "    result_df = result_each_target.groupby('Method').mean().reset_index()\n",
    "    order_dict = dict(zip(columns, range(len(columns))))\n",
    "    result_df['order'] = result_df['Method'].apply(lambda x: order_dict[x])\n",
    "    result_df = result_df.sort_values('order')\n",
    "    result_df = result_df.set_index('Method')\n",
    "    result_df = result_df.reset_index().drop('order', axis=1)\n",
    "    return result_df\n",
    "result_df = get_whole_result_from_each_target(result_each_target, methods + ['Random selection'])\n",
    "result_each_target = pd.merge(result_each_target, target_df, on='Target', how='left')\n",
    "# result_each_target.to_csv(score_dir / 'mqa_result_each_target_gdtts_5.csv')\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_each_target.query('Method == \"Random selection\"')[['Target', 'GDT_TS Loss']].sort_values('GDT_TS Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For models with pTMscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Against gdtts (For models by ptm models)\n",
    "label = 'GDT_TS'\n",
    "data = df[~df['pTM'].isna()].groupby('Target').filter(lambda x: x[label].max() - x[label].min() > 0.05)\n",
    "# excepted_targets = ['6Z4U_A', '6NEK_A']\n",
    "# data = data.query('Target not in @excepted_targets')\n",
    "result_each_target_ptm = eval_get_df(data, methods, label_name=label)\n",
    "result_df_ptm = get_whole_result_from_each_target(result_each_target_ptm, methods + ['Random selection'])\n",
    "result_each_target_ptm = pd.merge(result_each_target_ptm, target_df, on='Target', how='left')\n",
    "result_df_ptm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Against gdtts (For models by ptm models)\n",
    "label = 'GDT_TS'\n",
    "metric = 'Loss'\n",
    "sns.boxplot(data=result_each_target_ptm, x=f'{label} {metric}', y=f'Method', order=methods + ['Random selection'], color='white')\n",
    "sns.swarmplot(data=result_each_target_ptm, x=f'{label} {metric}', y=f'Method', order=methods + ['Random selection'], size=2, palette='deep')\n",
    "xticks = np.arange(-1, 6) * 10\n",
    "xticks_start = -6\n",
    "xticks[0] = xticks_start\n",
    "xticks_str = xticks.astype(str)\n",
    "xticks_str[0] = 'Mean'\n",
    "plt.xlim(-11, 60)\n",
    "plt.xticks(xticks, xticks_str)\n",
    "plt.axvline(x=xticks_start, color=(234/255,234/255,242/255))\n",
    "for i, method in enumerate(methods + ['Random selection']):\n",
    "    value = result_df_ptm.query('Method == @method')[f'{label} {metric}'].values[0]\n",
    "    plt.text(xticks_start, i, f'{value:.3f}', size=10, horizontalalignment='center', verticalalignment='center')\n",
    "plt.tight_layout()\n",
    "# plt.savefig(fig_dir / f'boxplot_{label}_{metric}_with_ptm.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['Pearson', 'Spearman']\n",
    "data = result_each_target_ptm\n",
    "label = 'GDT_TS'\n",
    "y = 'Method'\n",
    "for metric in metrics:\n",
    "    x = f'{label} {metric}'\n",
    "    sns.boxplot(data=data, x=x, y=y, order=methods, color='white')\n",
    "    sns.swarmplot(data=data, x=x, y=y, order=methods, size=3)\n",
    "    xticks_max = 1.2\n",
    "    plt.xlim(-1, 1.35)\n",
    "    xticks = np.append(np.arange(-1.0, 1.2, 0.5), [xticks_max])\n",
    "    xticks_str = list(map(lambda x: f'{x:.1f}', xticks))\n",
    "    xticks_str[-1] = 'Mean'\n",
    "    plt.xticks(xticks, xticks_str)\n",
    "    plt.axvline(x=xticks_max, color=(234/255,234/255,242/255))\n",
    "    mean_series = data.groupby(y).mean()[x]\n",
    "    for i, method in enumerate(methods):\n",
    "        value = mean_series[method]\n",
    "        plt.text(xticks_max, i, f'{value:.3f}', size=10, horizontalalignment='center', verticalalignment='center')\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig(fig_dir / f'boxplot_{label}_{metric}_ptm.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'GDT_TS'\n",
    "metric = 'Loss'\n",
    "plt.figure(figsize=(8, 5))\n",
    "order = [True, False]\n",
    "data = result_each_target_ptm\n",
    "sns.boxplot(data=data, x=f'{label} {metric}', y=f'Method', order=methods + ['Random selection'], hue='is_similar_AF2', color='white', hue_order=order)\n",
    "sns.swarmplot(data=data, x=f'{label} {metric}', y=f'Method', order=methods + ['Random selection'], size=1.5, hue='is_similar_AF2', dodge=True, hue_order=order)\n",
    "plt.tight_layout()\n",
    "# plt.savefig(fig_dir / f'boxplot_{label}_{metric}_similar_af2.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Against gdtts (For models by ptm models)\n",
    "labels = ['GDT_TS', 'Mean_LDDT', 'TMscore', 'GDT_HA']\n",
    "metrics = ['Pearson', 'Spearman', 'Loss', 'MAE']\n",
    "result_each_target_ptms = []\n",
    "for label in labels:\n",
    "    data = df[~df['pTM'].isna()].groupby('Target').filter(lambda x: x[label].max() - x[label].min() > 0.05)\n",
    "    result_each_target_ptm = eval_get_df(data, methods, label_name=label)\n",
    "    result_df_ptm = get_whole_result_from_each_target(result_each_target_ptm, methods + ['Random selection'])\n",
    "    display(result_df_ptm)\n",
    "    result_each_target_ptm = result_each_target_ptm.rename(columns={f'{label} {metric}': f'{metric}' for metric in metrics})\n",
    "    result_each_target_ptm['Label'] = label\n",
    "    result_each_target_ptms.append(result_each_target_ptm)\n",
    "result_each_target_ptm_each_label = pd.concat(result_each_target_ptms)\n",
    "result_each_target_ptm_each_label = pd.merge(result_each_target_ptm_each_label, target_df, on='Target', how='left')\n",
    "result_each_target_ptm_each_label.to_csv(score_dir / 'mqa_result_each_target_all_label_5_with_ptm.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MQA performance difference between is_similar_AF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Against gdtts\n",
    "label = 'GDT_TS'\n",
    "for name, group in df[~df['pTM'].isna()].groupby('is_similar_AF2'):\n",
    "    print(name)\n",
    "    data = group\n",
    "    result_df = eval(data, methods, label_name=label)\n",
    "    display(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Against gdtts (For targets whose value difference between max and min is larger than 0.05)\n",
    "label = 'GDT_TS'\n",
    "for name, group in df[~df['pTM'].isna()].groupby('is_similar_AF2'):\n",
    "    print(name)\n",
    "    data = group.groupby('Target').filter(lambda x: x[label].max() - x[label].min() > 0.05)\n",
    "    result_df = eval(data, methods, label_name=label)\n",
    "    display(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Mean_LDDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Against Mean LDDT\n",
    "label = 'Mean_LDDT'\n",
    "data = df[~df['pTM'].isna()].groupby('Target').filter(lambda x: x[label].max() - x[label].min() > 0.05)\n",
    "result_each_target = eval_get_df(data, methods, label_name=label)\n",
    "result_df = get_whole_result_from_each_target(result_each_target, methods + ['Random selection'])\n",
    "result_each_target = pd.merge(result_each_target, target_df, on='Target', how='left')\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'Mean_LDDT'\n",
    "metric = 'Loss'\n",
    "sns.boxplot(data=result_each_target, x=f'{label} {metric}', y=f'Method', order=methods + ['Random selection'], color='white')\n",
    "sns.swarmplot(data=result_each_target, x=f'{label} {metric}', y=f'Method', order=methods + ['Random selection'], size=2, palette='deep')\n",
    "xticks = np.arange(-1, 6) * 10\n",
    "xticks_start = -6\n",
    "xticks[0] = xticks_start\n",
    "xticks_str = xticks.astype(str)\n",
    "xticks_str[0] = 'Mean'\n",
    "plt.xlim(-11, 60)\n",
    "plt.xticks(xticks, xticks_str)\n",
    "plt.axvline(x=xticks_start, color=(234/255,234/255,242/255))\n",
    "# put parentheses around the pTMscore\n",
    "yticks, yticks_texts = plt.yticks()\n",
    "for i, ytick_text in enumerate(yticks_texts):\n",
    "    if ytick_text.get_text() == 'pTMscore':\n",
    "        yticks_texts[i] = '(pTMscore)'\n",
    "plt.yticks(yticks, yticks_texts)\n",
    "for i, method in enumerate(methods + ['Random selection']):\n",
    "    value = result_df.query('Method == @method')[f'{label} {metric}'].values[0]\n",
    "    plt.text(xticks_start, i, f'{value:.3f}', size=10, horizontalalignment='center', verticalalignment='center')\n",
    "plt.tight_layout()\n",
    "# plt.savefig(fig_dir / f'boxplot_{label}_{metric}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['Pearson', 'Spearman']\n",
    "data = result_each_target\n",
    "label = 'Mean_LDDT'\n",
    "y = 'Method'\n",
    "for metric in metrics:\n",
    "    x = f'{label} {metric}'\n",
    "    sns.boxplot(data=data, x=x, y=y, order=methods, color='white')\n",
    "    sns.swarmplot(data=data, x=x, y=y, order=methods, size=3)\n",
    "    xticks_max = 1.2\n",
    "    plt.xlim(-1, 1.35)\n",
    "    xticks = np.append(np.arange(-1.0, 1.2, 0.5), [xticks_max])\n",
    "    xticks_str = list(map(lambda x: f'{x:.1f}', xticks))\n",
    "    xticks_str[-1] = 'Mean'\n",
    "    plt.xticks(xticks, xticks_str)\n",
    "    plt.axvline(x=xticks_max, color=(234/255,234/255,242/255))\n",
    "    mean_series = data.groupby(y).mean()[x]\n",
    "    for i, method in enumerate(methods):\n",
    "        value = mean_series[method]\n",
    "        plt.text(xticks_max, i, f'{value:.3f}', size=10, horizontalalignment='center', verticalalignment='center')\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig(fig_dir / f'boxplot_{label}_{metric}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter plot between labels and MQA methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GDT_TS\n",
    "label = 'GDT_TS'\n",
    "ms = ['ProQ3D', 'VoroCNN', 'Sato-3DCNN', 'P3CMQA', 'DeepAccNet', 'DeepAccNet-Bert', 'pLDDT', 'pTM']\n",
    "# Fig size\n",
    "ncols = 4\n",
    "nrows = len(ms) // ncols\n",
    "xwidth = 22\n",
    "ywidth = xwidth * nrows / ncols\n",
    "figsize = (xwidth, ywidth)\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, sharex=False, sharey=False, figsize=figsize)\n",
    "data = df\n",
    "for i, method in enumerate(ms):\n",
    "    ax = axes[i // ncols, i % ncols]\n",
    "    sns.scatterplot(data=data, x=method, y=label, s=1, ax=axes[i // ncols, i % ncols])\n",
    "    d = data[~data[method].isna()]\n",
    "    x = d[method]\n",
    "    y = d[label]\n",
    "    corr = d.corr()[method][label]\n",
    "    mae = mean_absolute_error(x, y)\n",
    "    ax.set_xlabel(f'{method} (Cc: {corr:.3f}, MAE: {mae:.3f})')\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(0, 1)\n",
    "    x_latent = np.linspace(x.min(), x.max(), 100)\n",
    "    a, b = np.polyfit(x, y, 1)\n",
    "    y_latent = a * x_latent + b\n",
    "    ax.plot(x_latent, y_latent, 'r-')\n",
    "    ax.legend(['Linear fitting'])\n",
    "for i in range(len(ms), ncols * nrows):\n",
    "    ax = axes[i // ncols, i % ncols]\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "# plt.savefig(fig_dir / f'scatterplot_methods_{label}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GDT_TS with pTMscore\n",
    "label = 'GDT_TS'\n",
    "ms = ['ProQ3D', 'VoroCNN', 'Sato-3DCNN', 'P3CMQA', 'DeepAccNet', 'DeepAccNet-Bert', 'pLDDT', 'pTM']\n",
    "# Fig size\n",
    "ncols = 4\n",
    "nrows = len(ms) // ncols\n",
    "xwidth = 22\n",
    "ywidth = xwidth * nrows / ncols\n",
    "figsize = (xwidth, ywidth)\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, sharex=False, sharey=False, figsize=figsize)\n",
    "data = df[~df['pTM'].isna()]\n",
    "for i, method in enumerate(ms):\n",
    "    ax = axes[i // ncols, i % ncols]\n",
    "    sns.scatterplot(data=data, x=method, y=label, s=1, ax=axes[i // ncols, i % ncols])\n",
    "    d = data[~data[method].isna()]\n",
    "    x = d[method]\n",
    "    y = d[label]\n",
    "    corr = d.corr()[method][label]\n",
    "    mae = mean_absolute_error(x, y)\n",
    "    ax.set_xlabel(f'{method} (Cc: {corr:.3f}, MAE: {mae:.3f})')\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(0, 1)\n",
    "    x_latent = np.linspace(x.min(), x.max(), 100)\n",
    "    a, b = np.polyfit(x, y, 1)\n",
    "    y_latent = a * x_latent + b\n",
    "    ax.plot(x_latent, y_latent, 'r-')\n",
    "    ax.legend(['Linear fitting'])\n",
    "for i in range(len(ms), ncols * nrows):\n",
    "    ax = axes[i // ncols, i % ncols]\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "# plt.savefig(fig_dir / f'scatterplot_methods_{label}_with_ptm.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TMscore\n",
    "label = 'TMscore'\n",
    "# Fig size\n",
    "ncols = 4\n",
    "nrows = len(ms) // ncols\n",
    "xwidth = 22\n",
    "ywidth = xwidth * nrows / ncols\n",
    "figsize = (xwidth, ywidth)\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, sharex=False, sharey=False, figsize=figsize)\n",
    "data = df[~df['pTM'].isna()]\n",
    "for i, method in enumerate(ms):\n",
    "    ax = axes[i // ncols, i % ncols]\n",
    "    sns.scatterplot(data=data, x=method, y=label, s=1, ax=axes[i // ncols, i % ncols])\n",
    "    d = data[~data[method].isna()]\n",
    "    x = d[method]\n",
    "    y = d[label]\n",
    "    corr = d.corr()[method][label]\n",
    "    mae = mean_absolute_error(y, x)\n",
    "    ax.set_xlabel(f'{method} (Cc: {corr:.3f}, MAE: {mae:.3f})')\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(0, 1)\n",
    "    x_latent = np.linspace(x.min(), x.max(), 100)\n",
    "    a, b = np.polyfit(x, y, 1)\n",
    "    y_latent = a * x_latent + b\n",
    "    ax.plot(x_latent, y_latent, 'r-')\n",
    "    ax.legend(['Linear fitting'])\n",
    "for i in range(len(ms), ncols * nrows):\n",
    "    ax = axes[i // ncols, i % ncols]\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "# plt.savefig(fig_dir / f'scatterplot_methods_{label}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean LDDT\n",
    "label = 'Mean_LDDT'\n",
    "# Fig size\n",
    "ncols = 4\n",
    "nrows = len(ms) // ncols\n",
    "xwidth = 22\n",
    "ywidth = xwidth * nrows / ncols\n",
    "figsize = (xwidth, ywidth)\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, sharex=False, sharey=False, figsize=figsize)\n",
    "data = df[~df[label].isna()]\n",
    "data = data[~data['pTM'].isna()]\n",
    "for i, method in enumerate(ms):\n",
    "    ax = axes[i // ncols, i % ncols]\n",
    "    sns.scatterplot(data=data, x=method, y=label, s=1, ax=axes[i // ncols, i % ncols])\n",
    "    d = data[~data[method].isna()]\n",
    "    x = d[method]\n",
    "    y = d[label]\n",
    "    corr = d.corr()[method][label]\n",
    "    mae = mean_absolute_error(x, y)\n",
    "    ax.set_xlabel(f'{method} (Cc: {corr:.3f}, MAE: {mae:.3f})')\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(0, 1)\n",
    "    x_latent = np.linspace(x.min(), x.max(), 100)\n",
    "    a, b = np.polyfit(x, y, 1)\n",
    "    y_latent = a * x_latent + b\n",
    "    ax.plot(x_latent, y_latent, 'r-')\n",
    "    ax.legend(['Linear fitting'])\n",
    "for i in range(len(ms), ncols * nrows):\n",
    "    ax = axes[i // ncols, i % ncols]\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "# plt.savefig(fig_dir / f'scatterplot_methods_{label}.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "420aee174f128956f944742a33977e874aea80799cb0c4ab0861a75a155cece7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('mypython': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
